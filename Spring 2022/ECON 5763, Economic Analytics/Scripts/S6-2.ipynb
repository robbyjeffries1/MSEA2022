{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> Application of the Logit model (logistic regression) to Default Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/hj020/Desktop/2022/EconomicAnalytics-master/Python_/Data')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "raw0 = pd.read_csv('Default.csv')\n",
    "\n",
    "# drop the observations that contain missing values\n",
    "raw0.dropna()\n",
    "\n",
    "raw0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> 1) Produce descriptive statistics and visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> i) .describe()\n",
    "* panda .describe(): https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw0.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> ii) crosstab\n",
    "* Crosstab: https://pbpython.com/pandas-crosstab.html\n",
    "    - pd.crosstab(A,B): produce a frequency table with the groups in A on the rows and groups in B on the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(raw0.student,raw0.default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(raw0.student,raw0.default).plot(kind='bar')\n",
    "\n",
    "plt.title('Default Frequency')\n",
    "plt.xlabel('Student status')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> iii) Histogram\n",
    "* Histogram: https://jakevdp.github.io/PythonDataScienceHandbook/04.05-histograms-and-binnings.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3), dpi=100)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(raw0.balance.loc[raw0.default == 'No'],label='Non-defaulter',alpha=0.7) \n",
    "plt.hist(raw0.balance.loc[raw0.default == 'Yes'],label='Defaulter',alpha=0.7) \n",
    "plt.xlabel('Credit Card Balance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(raw0.income.loc[raw0.default == 'No'],label='Non-defaulter',alpha=0.7) \n",
    "plt.hist(raw0.income.loc[raw0.default == 'Yes'],label='Defaulter',alpha=0.7) \n",
    "plt.xlabel('Annual Income')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> iv) Boxplot\n",
    "* boxplot: https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = raw0.boxplot(column='balance', by=['default'], figsize=(6,6))\n",
    "boxplot = raw0.boxplot(column='income', by=['default'], figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> 2) Run a logistic regression on the default data\n",
    "\n",
    "* Two packages to run a logistic regression\n",
    "    - statsmodels: ***.Logit\n",
    "    - sklearn.linear_model: LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummies\n",
    "raw0.default=pd.get_dummies(raw0.default,drop_first=True) # default = 1\n",
    "raw0.student=pd.get_dummies(raw0.student,drop_first=True) # student = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a logistic regression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "Y = raw0.default\n",
    "X = raw0.iloc[:,2:]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "logitres=sm.Logit(Y,X).fit() # plug in Y first; case sensitive: Logit (o) logit(x)\n",
    "\n",
    "print(logitres.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression with interaction and higer order\n",
    "\n",
    "logitres2=smf.logit('default ~ student + income + balance + student*balance + student*income + np.power(income,2) + np.power(balance,2)', data=raw0).fit() # logit (o), Logit(x)\n",
    "\n",
    "print(logitres2.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> 3) Calculate/show default probability for students and non-students, separately, as a function of balance, holding income at its mean\n",
    "\n",
    "* see the lecture note 6, page 6-7 (or textbook chapter 4.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid0 = np.linspace(raw0.balance.min(), raw0.balance.max(), 100).reshape((100,1))\n",
    "xx1 = np.concatenate((np.ones((100,1)),np.ones((100,1)),grid0,np.ones((100,1))*raw0.income.mean()), axis=1)\n",
    "xx2 = np.concatenate((np.ones((100,1)),np.zeros((100,1)),grid0,np.ones((100,1))*raw0.income.mean()), axis=1)\n",
    "prd1 = logitres.predict(xx1)\n",
    "prd2 = logitres.predict(xx2)\n",
    "\n",
    "plt.figure(figsize=(8, 7), dpi=80)\n",
    "plt.plot(grid0,prd1,label='Student')\n",
    "plt.plot(grid0,prd2,label='Non-student')\n",
    "plt.xlabel('Balance')\n",
    "plt.ylabel('Prob of Default')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> 4) Calculate marginal effect of a variable on default probability\n",
    "\n",
    "* For the calculation of marginal effect of a continuous variable (e.g. balance or income) on default probability, \n",
    "    \n",
    "    1. you can use the formula (1) on page 6 of the lecture note 6. \n",
    "    2. Or you can use \".get_margeff( )\" function in statsmodels \n",
    "     * see: https://towardsdatascience.com/binary-logistic-regression-using-python-research-oriented-modelling-and-interpretation-49b025f1b510 and https://www.statsmodels.org/stable/generated/statsmodels.discrete.discrete_model.DiscreteResults.get_margeff.html\n",
    "     * However, remember that the five different types of the marginal effects calculated from the \".get_margeff( )\" doesn't include the marginal effect computed by the formula (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meff=logitres.get_margeff(at = 'mean', method = 'dydx', dummy = True)\n",
    "print(meff.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkred'> HW6: Calculate the marginal effect of the student status on default probability, holding income and balance at their means, using the formula (2) on page 7 of the lecture note 6\n",
    "\n",
    "* Note that the student variable is binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> 5) Evaluate the logit regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> i) Out of sample prediction accuracy: test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: logit in statsmodels provides the summary table but logit in sklearn.linear_model doesn't.\n",
    "# However, logit in sklearn.linear_model has some useful attributes like prediction score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "logreg = LogisticRegression(fit_intercept=0, solver = 'lbfgs').fit(X_train, y_train)\n",
    "\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> ii) Confusion Matrix\n",
    "    \n",
    "* https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = logreg.predict(X_test) # prediction\n",
    "cm_logit = confusion_matrix(y_test, y_pred)\n",
    "print(cm_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA) and K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Application of LDA and QDA to the default data\n",
    "\n",
    "* LDA: https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\n",
    "* QDA: https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis\n",
    "* Visualization of LDA \\& QDA: https://scikit-learn.org/stable/auto_examples/classification/plot_lda_qda.html#sphx-glr-auto-examples-classification-plot-lda-qda-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "X_train=X_train.drop('const', axis=1) # An intercept will be automatically included in the model, so we need to remove it from X\n",
    "X_test=X_test.drop('const', axis=1)\n",
    "\n",
    "# test error\n",
    "LDAres = LDA().fit(X_train, y_train)\n",
    "QDAres = QDA().fit(X_train, y_train)\n",
    "\n",
    "print(LDAres.score(X_test, y_test))\n",
    "print(QDAres.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "y_pred_LDA = LDAres.predict(X_test)\n",
    "\n",
    "y_pred_QDA = QDAres.predict(X_test)\n",
    "\n",
    "cm_LDA = confusion_matrix(y_test, y_pred_LDA)\n",
    "print(cm_LDA)\n",
    "cm_QDA = confusion_matrix(y_test, y_pred_QDA)\n",
    "print(cm_QDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Application of KNN to the default data\n",
    "* KNN: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "* Visualization of KNN: https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNNC\n",
    "\n",
    "# test error\n",
    "KNNCres = KNNC(n_neighbors = 5).fit(X_train, y_train)\n",
    "print(KNNCres.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "y_pred_KNNC = KNNCres.predict(X_test)\n",
    "\n",
    "cm_KNNC = confusion_matrix(y_test, y_pred_KNNC)\n",
    "print(cm_KNNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkred'> HW6-2: Optimize/tune the number of neighbors of KNN using cross-validation\n",
    "    \n",
    "* Use the function \"GridSearchCV\" in scikitlearn:\n",
    "    - Manual: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "    - An example: https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
    "* Use \"precision\" to evaluate the prediction performance at each number of neighbors\n",
    "* Use the default data\n",
    "* Visualize your results using a graph which plot the prediction performances at the numbers of neigbors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
