{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> Application of Random Forest and Boosted Trees to the Classification of Web Documents\n",
    "* Introduction of ensemble methods in python: https://scikit-learn.org/stable/modules/ensemble.html#ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/hj020/Desktop/2022/EconomicAnalytics-master/Python_/Data')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Data Preparation: 20 news group data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "categories = ['alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space']\n",
    "\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove, shuffle=True, random_state=42)\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories, remove=remove, shuffle=True, random_state=42)\n",
    "\n",
    "Y_train, Y_test = data_train.target, data_test.target\n",
    "\n",
    "X_train = data_train.data\n",
    "X_test = data_test.data\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train) \n",
    "X_test = vectorizer.transform(X_test)\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> 1) Random Forests\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=1000, max_depth=None, max_features = math.floor(math.sqrt(n_features)), min_samples_split = 2)\n",
    "\n",
    "RFres= RF.fit(X_train, Y_train)\n",
    "\n",
    "print(RFres.score(X_test, Y_test))\n",
    "print(classification_report(Y_test, RFres.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> * Relative Influence Plot\n",
    "* An example: https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> i) Extract 10 most important features (words) in terms of their importance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = RFres.feature_importances_ # importance scores for all the words used for classification\n",
    "\n",
    "# Sort the importance scores in ascending order and select the bottom 10 items and then reverse the list\n",
    "# This involves many steps because there is no option for a descending sort in np.sort (this may be done by -np.sort(-importances))\n",
    "top10v = np.sort(importances)[-10:][::-1] \n",
    "top10n = np.argsort(importances)[-10:][::-1] # Original indices for the sorted scores\n",
    "\n",
    "feature_names = np.asarray(vectorizer.get_feature_names()) # Words used for classification by the vectorizer\n",
    "\n",
    "print(feature_names[top10n]) # Sort feature names by the sorted order above\n",
    "print(top10v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> ii) Plot a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for f in range(10):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, feature_names[top10n[f]], top10v[f]))\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.title(\"Feature Importance Chart\",  fontsize=20)\n",
    "plt.bar(feature_names[top10n], top10v, color=\"r\")\n",
    "plt.xticks(fontsize= 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> 2) Boosted Trees using Gradient Boosting\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n",
    "    - $B$ : n_estimators, default=100\n",
    "    - $\\lambda$ : learning_rate, default=0.1\n",
    "    - The (maximum) number of splits in a tree: max_depth, default=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GB = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.5, max_depth=2)\n",
    "\n",
    "GBres = GB.fit(X_train, Y_train)\n",
    "\n",
    "print(GBres.score(X_test, Y_test))\n",
    "print(classification_report(Y_test, GBres.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkred'> HW8: Similarly to the figure 8.11 on p.324 of the textbook, make a plot which shows the relationships between the number of trees and out of sample classification accuracy for random forest and gradient boosting \n",
    "- You may use the GridsearchCV function for this exercise. In this case, set scoring = 'accuracy'\n",
    "- You may also manually use a for-loop. In this case, use \" .score()\" function to compute out of sample classification accuracies\n",
    "- You can use any set of values for the number of trees (e.g. n_estimators=[10, 50, 100, 500, 1000 ....]), but you may want to use a fine grid to produce a better plot\n",
    "- Put number of trees on x-axis and classification accuracy on y-axis\n",
    "- Set max_depth=None, max_features = math.floor(math.sqrt(n_features)), min_samples_split = 2 for random forest\n",
    "- Set learning_rate=0.5, max_depth=2 for gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> Web Scraping\n",
    "* Web scraping using BeautifulSoup: https://www.freecodecamp.org/news/how-to-scrape-websites-with-python-and-beautifulsoup-5946935d93fe/\n",
    "* Web scraping using Scrapy:https://www.analyticsvidhya.com/blog/2017/07/web-scraping-in-python-using-scrapy/\n",
    "* Web scrapers: https://www.scraperapi.com/blog/the-10-best-web-scraping-tools (including commercial scrapers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify a url\n",
    "quote_page = 'https://www.uark.edu/academics/majors.php'\n",
    "    \n",
    "response = requests.get(quote_page)\n",
    "\n",
    "# Get the web page in html and convert it to a BeautifulSoup format\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the address of the part you want to scrap using \"inspect\" function in your web browser\n",
    "# For this, the inspection function should be manually enabled in your brower\n",
    "# Plug the address in \"find\"\n",
    "\n",
    "name_box = soup.find('p', {'class' : 'bigCopy'})\n",
    "name_box\n",
    "name = name_box.text.strip() # strip() is used to remove spaces at the beginning and at the end of the string\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the text\n",
    "ark = [name] \n",
    "arkk=vectorizer.transform(ark)\n",
    "print(arkk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFres.predict(arkk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
