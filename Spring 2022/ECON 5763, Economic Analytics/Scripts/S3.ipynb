{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> Least Squares Estimation using Matrix Algebra and Numerical Optimization\n",
    "\n",
    "* Lecture note 2: p.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/hj020/Desktop/2022/EconomicAnalytics-master/Python_/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math \n",
    "\n",
    "raw0 = pd.read_csv('College.csv')\n",
    "raw0['Private']=pd.get_dummies(raw0['Private'],drop_first=True)\n",
    "raw0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> 1) Least Squares Estimation using Matrix Algebra\n",
    "\n",
    "https://web.stanford.edu/~mrosenfe/soc_meth_proj3/matrix_OLS_NYU_notes.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe to a numpy array (excluding the first column-college names)\n",
    "raw00 = raw0.iloc[:,1:].values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can suppress scientific notation using \"np.set_printoptions\" (e.g. np.set_printoptions(precision=2, suppress=True))\n",
    "* Scientific notation: https://en.wikipedia.org/wiki/Scientific_notation\n",
    "* np.set_printoptions: https://numpy.org/doc/stable/reference/generated/numpy.set_printoptions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct X matrix\n",
    "X=raw00[:,(4,0,8,11,16)] # select predictors (note that the first column was removed)\n",
    "nrow = X.shape[0]\n",
    "intcpt = np.ones( (nrow,1), ) # create an intercept\n",
    "X = np.concatenate((intcpt, X), axis=1) # add the intercept to X (i.e X = [intcpt,X] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Y vector\n",
    "Y=raw00[:,15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The code above didn't specify whether it is a row or column vector\n",
    "* Use Y=raw00[:,[15]] to specify it is a column vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color='green'> i) Compute LS estimates\n",
    "\n",
    "$\\hat{\\beta} = (X^{'}X)^{-1}X^{'}Y$\n",
    "    \n",
    "* inv( ) from numpy.linalg\n",
    "* transpose function\n",
    "* matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "OLSres = inv(X.T@X)@(X.T@Y)\n",
    "print(OLSres) # Compare this to the previous result obtained from the statsmodels package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color='green'> ii) Compute the Standard Errors of the Estimates & t-statistics\n",
    "\n",
    "$\\hat{\\sigma}_{\\beta} = Diag \\left(\\sqrt{\\hat{\\sigma}^2(X^{'}X)^{-1}} \\right)$ where $\\hat{\\sigma}^2 = \\hat{U}^{'}\\hat{U}/(n-p-1)$ and $\\hat{U} = Y - X\\hat{\\beta}$\n",
    "    \n",
    "$t_{\\beta} = | \\hat{\\beta}/\\hat{\\sigma}_{\\beta} |$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Residuals\n",
    "resid = Y-X@OLSres\n",
    "# Calculate SER (Standard error of the regression)\n",
    "SER = (resid.T@resid)/(nrow-X.shape[1])\n",
    "# Calculate SE\n",
    "SE = np.sqrt(np.diag(SER*inv(X.T@X))) # Compare this to the previous result from the statsmodels package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate T statistics\n",
    "Tstat = abs(OLSres/SE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> 2) Least Squares Estimation using Numerical Optimization\n",
    "\n",
    "$\\hat{\\beta} = argmin_{\\beta} (Y - X\\beta)^{'}(Y - X\\beta)/n$\n",
    "    \n",
    "* Newton Method : https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization\n",
    "* Optimization in Python: https://scipy-lectures.org/advanced/mathematical_optimization/ & https://realpython.com/python-scipy-cluster-optimize/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss fn in two ways\n",
    "\n",
    "# loss function 1\n",
    "def loss(inpt,Y,X):\n",
    "    nrow=Y.shape[0]\n",
    "    loss0=0\n",
    "\n",
    "    for i in range(0,nrow):\n",
    "        \n",
    "            resid = Y[i]-X[i,:]@inpt\n",
    "            loss0 = loss0+resid*resid\n",
    "            # can be done simply: loss0+=resid*resid (add and assign)\n",
    "            \n",
    "    return loss0\n",
    "\n",
    "# loss function 2\n",
    "def loss2(inpt,Y,X):\n",
    "\n",
    "    resid = Y-X@inpt\n",
    "    loss0 = resid.T@resid\n",
    "            \n",
    "    return loss0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Optimizer \"fmin\" : https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize\n",
    "inpt = np.zeros((X.shape[1],1)) # starting value\n",
    "OLSres2=optimize.fmin(loss2,\n",
    "                      inpt,\n",
    "                      args=(Y,X),\n",
    "                      maxfun=40000,\n",
    "                      maxiter=40000,\n",
    "                      ftol=1e-10,\n",
    "                      xtol=1e-10,\n",
    "                      disp=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OLSres2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkred'> HW3\n",
    "* Pick one of your linear regression models in HW2 \n",
    "* Compute least squares estimates, standard errors of the estimates and t-statistics <ins> using the matrix algebra and optimization algorithm as described above </ins>\n",
    "* Compare them to the results previously obtained from the statsmodels package"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
