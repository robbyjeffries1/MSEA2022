{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> Application of the LASSO to Boston Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/hj020/Desktop/2022/EconomicAnalytics-master/Python_/Data')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "raw0 = pd.read_csv('Boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store variable names for labeling later\n",
    "varname=list(raw0.iloc[:,1:-1].columns)\n",
    "\n",
    "# Define y and X (including all the regressors)\n",
    "raw0 = raw0.iloc[:,1:].values\n",
    "Y = raw0[:,-1]\n",
    "X = raw0[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> 1) Lasso Estimation with a Preselected Tuning Parameter Value ($\\lambda$)\n",
    "\n",
    "Parameters in linear_model.Lasso: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "las = linear_model.Lasso(alpha=0.5).fit(X,Y) # alpha is the tuning parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(las.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> 2) Computation of a Lasso Solution Path\n",
    "Parameters and returns in lasso_path: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.lasso_path.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import lasso_path\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use \"eps\" to specify the length and density of the grid (eps = alpha_min / alpha_max)\n",
    "eps = 1e-10  \n",
    "alphas_lasso, coefs_lasso, _ = lasso_path(X, Y, eps = eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alphas_lasso) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coefs_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row of \"coefs_lasso\" contains a series of estimates for a coefficient over the grid\n",
    "# Each column contains coefficient etimates at each lambda value\n",
    "print(coefs_lasso[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the solution path\n",
    "plt.figure(figsize=(8, 7), dpi=80)\n",
    "colors = cycle(['b', 'r', 'g', 'c','m', 'y', 'k'])\n",
    "\n",
    "# Take the log of the alpha values to adjust the scale of X-axis\n",
    "log_alphas_lasso = np.log10(alphas_lasso) \n",
    "\n",
    "# Use a for-loop to plot several paths on a figure \n",
    "for coef_l, c, vn in zip(coefs_lasso, colors, varname):\n",
    "    l1 = plt.plot(log_alphas_lasso, coef_l, c=c, label=vn)\n",
    "    \n",
    "plt.xlabel('Log(alpha)')\n",
    "plt.ylabel('Coefficient Estimtes')\n",
    "plt.title('Lasso Solution Path')\n",
    "plt.legend()\n",
    "plt.savefig('lassopath.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> 3) Selection of a Tuning Parameter Value (= Selection of a Model) in the LASSO using CV/BIC/AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoLarsCV, LassoLarsIC\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> i) Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time() # Get the current time\n",
    "lascv = LassoLarsCV(cv=5).fit(X, Y)\n",
    "t_lasso_lars_cv = time.time() - t1 # Calculate running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results\n",
    "eps = 5e-10\n",
    "lascv_log_alphas = np.log10(lascv.cv_alphas_ + eps) \n",
    "lascv_log_alpha = np.log10(lascv.alpha_)\n",
    "# Caution: lascv.alphas contains the alpha at the lowest MSE whereas lascv.cv_alphas_ contains the set of alphas used in the path\n",
    "# The smallest value in lascv.cv_alphas_ is 0 so we add eps (a small number) to avoid log(0)\n",
    "\n",
    "plt.figure(figsize=(8, 7), dpi=80)\n",
    "plt.plot(lascv_log_alphas, lascv.mse_path_.mean(axis=1), 'k',\n",
    "         label='Average of the MSEs over the Folds', linewidth=2)\n",
    "plt.axvline(lascv_log_alpha, linestyle='--', color='k',\n",
    "            label='alpha selected by CV')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Log(alpha)')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.title('Model Selection by Cross Validation (train time: %.2fs)'\n",
    "          % t_lasso_lars_cv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Lasso estimates at the alpha selected by CV\n",
    "print(lascv.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'> ii) BIC and AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasic_bic = LassoLarsIC(criterion='bic').fit(X, Y)\n",
    "lasic_aic = LassoLarsIC(criterion='aic').fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "# make a fn to produce figures with the same features repeatedly\n",
    "def plot_ic_criterion(model, name, color): \n",
    "    alpha_ = model.alpha_ + eps\n",
    "    alphas_ = model.alphas_ + eps\n",
    "    criterion_ = model.criterion_ # BIC or AIC values over the alpha values\n",
    "    plt.plot(np.log10(alphas_), criterion_, '--', color=color,\n",
    "             linewidth=3, label='%s' % name)\n",
    "    plt.axvline(np.log10(alpha_), color=color, linewidth=3,\n",
    "                label='$\\lambda$ selected by %s ' % name)\n",
    "    plt.xlabel('Log($\\lambda$)')\n",
    "    plt.ylabel('Criterion Value')\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(8, 7), dpi=80)\n",
    "plot_ic_criterion(lasic_aic, 'AIC', 'b')\n",
    "plot_ic_criterion(lasic_bic, 'BIC', 'r')\n",
    "plt.legend()\n",
    "plt.title('Model Selection by Information Criteria')\n",
    "#plt.show()\n",
    "plt.savefig('lasso.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Lasso estimates at the alpha selected by AIC and BIC\n",
    "print(lasic_aic.coef_)\n",
    "print(lasic_bic.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkred'> HW5\n",
    "    \n",
    "* Use the dataset, \"Hitters.csv\", posted on BB to explain/predict a baseball playerâ€™s salary <u> using a subset of covariates in the dataset </u>.\n",
    "    \n",
    "* In order to select a subset of covariates, do the following:\n",
    "    - Forward and backward stepwise selections based on AIC and BIC\n",
    "    - LASSO Estimations with CV, AIC and BIC\n",
    "    - Produce tables or figures or both to summarize your results\n",
    "    \n",
    "* For this exercise, you need to take care of missing values and also generate dummies for some variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
